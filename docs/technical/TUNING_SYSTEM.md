# üéØ Syst√®me de Tuning Normalization - Documentation Technique

**Version** : 1.0

**Date** : 27 d√©cembre 2025

**Owner** : Thomas

**ADR** : ADR_004_normalization_tuning_system.md

---

## Table des Mati√®res

1. [Vision Globale](https://claude.ai/chat/dd173dbf-94b5-4721-9cd2-57561c855cc1#vision-globale)
2. [Architecture Syst√®me](https://claude.ai/chat/dd173dbf-94b5-4721-9cd2-57561c855cc1#architecture-syst%C3%A8me)
3. [Composants D√©taill√©s](https://claude.ai/chat/dd173dbf-94b5-4721-9cd2-57561c855cc1#composants-d%C3%A9taill%C3%A9s)
4. [Flow de Donn√©es](https://claude.ai/chat/dd173dbf-94b5-4721-9cd2-57561c855cc1#flow-de-donn%C3%A9es)
5. [Impl√©mentation Code](https://claude.ai/chat/dd173dbf-94b5-4721-9cd2-57561c855cc1#impl%C3%A9mentation-code)
6. [Roadmap](https://claude.ai/chat/dd173dbf-94b5-4721-9cd2-57561c855cc1#roadmap)
7. [Monitoring &amp; M√©triques](https://claude.ai/chat/dd173dbf-94b5-4721-9cd2-57561c855cc1#monitoring--m%C3%A9triques)
8. [Troubleshooting](https://claude.ai/chat/dd173dbf-94b5-4721-9cd2-57561c855cc1#troubleshooting)

---

## Vision Globale

### Objectif

Cr√©er un syst√®me hybride de normalisation textile (FR‚ÜíEN) qui :

* Garantit **95%+ quality** d√®s MVP
* Co√ªte **<$10/mois** (d√©croissant vers $2/mois)
* N√©cessite **<30 min/semaine** maintenance
* S'**auto-am√©liore** progressivement

### Probl√®me R√©solu

**Avant** :

```
Quality Score: 70%
Materials d√©tect√©s: 80%
Colors d√©tect√©s: 40%
```

**Apr√®s** (MVP) :

```
Quality Score: 95%+
Materials d√©tect√©s: 95%+
Colors d√©tect√©s: 90%+
```

---

## Architecture Syst√®me

### Vue d'Ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   PRODUCTION LAYER                        ‚îÇ
‚îÇ              (Scraping Temps R√©el)                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ  ‚îÇ  Textile   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Normalize   ‚îÇ                ‚îÇ
‚îÇ  ‚îÇ  Brut (FR) ‚îÇ         ‚îÇ  Function   ‚îÇ                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ                                 ‚îÇ                        ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ                          ‚îÇ Dictionary  ‚îÇ                ‚îÇ
‚îÇ                          ‚îÇ  Try Match  ‚îÇ                ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ                                 ‚îÇ                        ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ                    ‚îÇ                         ‚îÇ          ‚îÇ
‚îÇ               FOUND (85%)              NOT FOUND (15%)  ‚îÇ
‚îÇ                    ‚îÇ                         ‚îÇ          ‚îÇ
‚îÇ                    ‚ñº                         ‚ñº          ‚îÇ
‚îÇ            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ            ‚îÇ Return Dict  ‚îÇ          ‚îÇ LLM Fallback‚îÇ   ‚îÇ
‚îÇ            ‚îÇ  Value (EN)  ‚îÇ          ‚îÇ  API Call   ‚îÇ   ‚îÇ
‚îÇ            ‚îÇ   1ms, $0    ‚îÇ          ‚îÇ   2s, $0.003‚îÇ   ‚îÇ
‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                    ‚îÇ                         ‚îÇ          ‚îÇ
‚îÇ                    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                    ‚îÇ         ‚îÇ  Log Unknown             ‚îÇ
‚îÇ                    ‚îÇ         ‚ñº                           ‚îÇ
‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ                    ‚îÇ  ‚îÇ unknown_terms‚îÇ                  ‚îÇ
‚îÇ                    ‚îÇ  ‚îÇ   Database   ‚îÇ                  ‚îÇ
‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ                    ‚îÇ                                     ‚îÇ
‚îÇ                    ‚ñº                                     ‚îÇ
‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ           ‚îÇ Normalized (EN)  ‚îÇ                          ‚îÇ
‚îÇ           ‚îÇ   Insert to DB   ‚îÇ                          ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              SUPERVISION LAYER                            ‚îÇ
‚îÇ          (Asynchrone, 1-2√ó/semaine)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ
‚îÇ  ‚îÇ Review Alert ‚îÇ                                       ‚îÇ
‚îÇ  ‚îÇ 20+ unknowns ‚îÇ                                       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                       ‚îÇ
‚îÇ         ‚îÇ                                               ‚îÇ
‚îÇ         ‚ñº                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
‚îÇ  ‚îÇ Admin UI /tuning   ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ List unknowns    ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Batch LLM call   ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Review context   ‚îÇ                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
‚îÇ         ‚îÇ                                               ‚îÇ
‚îÇ         ‚ñº                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
‚îÇ  ‚îÇ Human Decision     ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚úì Approve          ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚úó Reject           ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚úèÔ∏è Edit/Custom      ‚îÇ                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
‚îÇ         ‚îÇ                                               ‚îÇ
‚îÇ         ‚ñº                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
‚îÇ  ‚îÇ Update Dictionary  ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ + Regex patterns   ‚îÇ                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
‚îÇ         ‚îÇ                                               ‚îÇ
‚îÇ         ‚ñº                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
‚îÇ  ‚îÇ Non-Regression Test‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Re-normalize all ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Detect changes   ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Show impact      ‚îÇ                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
‚îÇ         ‚îÇ                                               ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                         ‚îÇ
‚îÇ    ‚ñº         ‚ñº                                          ‚îÇ
‚îÇ  [OK]    [ROLLBACK]                                    ‚îÇ
‚îÇ    ‚îÇ                                                    ‚îÇ
‚îÇ    ‚ñº                                                    ‚îÇ
‚îÇ  Deploy                                                ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Composants D√©taill√©s

### 1. Dictionnaire de Production

#### Structure Fichier

**Location** : `src/lib/scraping/common/dictionaries/`

```
dictionaries/
‚îú‚îÄ‚îÄ index.ts              # Export central
‚îú‚îÄ‚îÄ materials.ts          # Mat√©riaux
‚îú‚îÄ‚îÄ colors.ts             # Couleurs
‚îú‚îÄ‚îÄ patterns.ts           # Motifs
‚îî‚îÄ‚îÄ types.ts              # TypeScript interfaces
```

#### Format Data

```typescript
// types.ts
export interface DictionaryEntry {
  value: string;              // Traduction EN
  source: 'manual' | 'llm_suggested' | 'user_feedback';
  confidence: number;         // 0-1
  validated_at: string;       // ISO date
  validated_by: string;       // User ID
  occurrences?: number;       // Combien de fois utilis√©
  notes?: string;             // Notes humain
}

export interface RegexPattern {
  regex: RegExp;
  value: string;
  source: string;
  priority: number;           // Pour r√©solution conflits
}

export interface Dictionary {
  exact: Record<string, DictionaryEntry>;
  patterns: RegexPattern[];
}
```

```typescript
// materials.ts
import { Dictionary } from './types';

export const materials: Dictionary = {
  exact: {
    // Manuels (Phase 1)
    "coton": {
      value: "cotton",
      source: "manual",
      confidence: 1.0,
      validated_at: "2025-12-27",
      validated_by: "thomas",
      occurrences: 45
    },
  
    "soie": {
      value: "silk",
      source: "manual",
      confidence: 1.0,
      validated_at: "2025-12-27",
      validated_by: "thomas",
      occurrences: 32
    },
  
    // LLM suggested (Phase 2+)
    "lilas": {
      value: "lilac",
      source: "llm_suggested",
      confidence: 0.98,
      validated_at: "2025-12-28",
      validated_by: "thomas",
      notes: "LLM suggestion approved after review"
    },
  
    "bouclette": {
      value: "boucle",
      source: "llm_suggested",
      confidence: 0.92,
      validated_at: "2025-12-28",
      validated_by: "thomas"
    }
  },
  
  // Regex patterns (Phase 5+)
  patterns: [
    {
      regex: /100%?\s*coton/i,
      value: "cotton",
      source: "manual",
      priority: 10
    },
    {
      regex: /(\d+)%?\s*soie/i,
      value: "silk",
      source: "manual",
      priority: 10
    },
    {
      regex: /boucl(e|ette)/i,
      value: "boucle",
      source: "llm_suggested",
      priority: 5
    }
  ]
};
```

#### Fonction Normalize

```typescript
// src/lib/scraping/common/normalize.ts

import { materials, colors, patterns } from './dictionaries';

interface NormalizeOptions {
  enableLLMFallback?: boolean; // Default true en production
  logUnknowns?: boolean;        // Default true
}

export async function extractMaterialType(
  text: string,
  options: NormalizeOptions = {}
): Promise<string | null> {
  
  const { enableLLMFallback = true, logUnknowns = true } = options;
  
  const normalized = text.toLowerCase().trim();
  
  // 1. Try exact match
  if (materials.exact[normalized]) {
    const entry = materials.exact[normalized];
  
    // Update occurrences (optional, for analytics)
    entry.occurrences = (entry.occurrences || 0) + 1;
  
    return entry.value;
  }
  
  // 2. Try regex patterns (sorted by priority)
  const sortedPatterns = [...materials.patterns].sort((a, b) => 
    b.priority - a.priority
  );
  
  for (const pattern of sortedPatterns) {
    if (pattern.regex.test(normalized)) {
      return pattern.value;
    }
  }
  
  // 3. Dictionary miss
  if (enableLLMFallback) {
    // LLM fallback (async)
    const llmResult = await normalizWithLLM(text, 'material');
  
    if (logUnknowns) {
      await logUnknownTerm({
        term: text,
        category: 'material',
        llm_suggestion: llmResult.value,
        llm_confidence: llmResult.confidence
      });
    }
  
    return llmResult.value;
  }
  
  // 4. No fallback ‚Üí log and return null
  if (logUnknowns) {
    await logUnknownTerm({
      term: text,
      category: 'material'
    });
  }
  
  return null;
}
```

---

### 2. LLM Fallback Service

#### Configuration

```typescript
// src/lib/ai/config.ts

export const LLM_CONFIG = {
  provider: 'anthropic',
  model: 'claude-sonnet-4-20250514',
  max_tokens: 300,
  temperature: 0.1, // Low pour d√©terminisme
  timeout: 5000, // 5s max
  retries: 2
};

export const PROMPT_TEMPLATES = {
  material: `You are a textile terminology expert.

TASK: Translate this French textile term to English.

TERM: "{{term}}"
CATEGORY: material

CONTEXT (if available): "{{context}}"

RULES:
- Use standard textile industry terminology
- Provide the most common English equivalent
- Be concise (1-3 words maximum)
- Consider the textile context

RESPOND in JSON format only:
{
  "value": "english_term",
  "confidence": 0.95,
  "reasoning": "brief explanation"
}

Example:
Input: "lilas clair"
Output: {"value": "light lilac", "confidence": 0.95, "reasoning": "lilas is lilac in French, clair means light"}`,

  color: `You are a textile color expert.

TASK: Translate this French color term to English.

TERM: "{{term}}"
CATEGORY: color

CONTEXT (if available): "{{context}}"

RULES:
- Use standard color names
- Be specific if the term indicates a specific shade
- Keep it concise

RESPOND in JSON format only:
{
  "value": "english_color",
  "confidence": 0.95,
  "reasoning": "brief explanation"
}`,
  
  pattern: `You are a textile pattern expert.

TASK: Translate this French pattern/motif term to English.

TERM: "{{term}}"
CATEGORY: pattern

RULES:
- Use standard textile pattern terminology
- Examples: stripes, floral, geometric, paisley

RESPOND in JSON format only:
{
  "value": "english_pattern",
  "confidence": 0.95,
  "reasoning": "brief explanation"
}`
};
```

#### Service Implementation

```typescript
// src/lib/ai/normalize-llm.ts

import Anthropic from '@anthropic-ai/sdk';
import { LLM_CONFIG, PROMPT_TEMPLATES } from './config';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY
});

interface LLMResult {
  value: string;
  confidence: number;
  reasoning: string;
  cost: number; // Pour tracking
}

export async function normalizWithLLM(
  term: string,
  category: 'material' | 'color' | 'pattern',
  context?: string
): Promise<LLMResult> {
  
  // Build prompt from template
  const template = PROMPT_TEMPLATES[category];
  const prompt = template
    .replace('{{term}}', term)
    .replace('{{context}}', context || 'N/A');
  
  try {
    const message = await anthropic.messages.create({
      model: LLM_CONFIG.model,
      max_tokens: LLM_CONFIG.max_tokens,
      temperature: LLM_CONFIG.temperature,
      messages: [{
        role: 'user',
        content: prompt
      }]
    });
  
    // Parse response
    const content = message.content[0];
    if (content.type !== 'text') {
      throw new Error('Unexpected response type');
    }
  
    const parsed = JSON.parse(content.text);
  
    // Calculate cost (approximation)
    const inputTokens = message.usage.input_tokens;
    const outputTokens = message.usage.output_tokens;
    const cost = (inputTokens * 0.000003) + (outputTokens * 0.000015);
  
    return {
      value: parsed.value,
      confidence: parsed.confidence || 0.9,
      reasoning: parsed.reasoning || '',
      cost
    };
  
  } catch (error) {
    console.error('LLM normalization error:', error);
  
    // Fallback strategy
    return {
      value: term, // Return as-is
      confidence: 0.1,
      reasoning: 'LLM call failed, returning original term',
      cost: 0
    };
  }
}

// Batch version (pour supervision)
export async function normalizeBatch(
  terms: Array<{term: string, category: string, context?: string}>
): Promise<LLMResult[]> {
  
  // Build batch prompt
  const batchPrompt = `You are a textile terminology expert.
Translate these French textile terms to English.

TERMS:
${terms.map((t, i) => `${i+1}. "${t.term}" (${t.category})`).join('\n')}

RESPOND with a JSON array:
[
  {"term": "lilas", "value": "lilac", "confidence": 0.95, "reasoning": "..."},
  {"term": "√©cru", "value": "ecru", "confidence": 0.98, "reasoning": "..."},
  ...
]`;

  try {
    const message = await anthropic.messages.create({
      model: LLM_CONFIG.model,
      max_tokens: 2000,
      temperature: LLM_CONFIG.temperature,
      messages: [{
        role: 'user',
        content: batchPrompt
      }]
    });
  
    const content = message.content[0];
    if (content.type !== 'text') {
      throw new Error('Unexpected response type');
    }
  
    const results = JSON.parse(content.text);
  
    // Calculate per-item cost
    const totalCost = (message.usage.input_tokens * 0.000003) + 
                     (message.usage.output_tokens * 0.000015);
    const costPerItem = totalCost / terms.length;
  
    return results.map((r: any) => ({
      ...r,
      cost: costPerItem
    }));
  
  } catch (error) {
    console.error('Batch LLM normalization error:', error);
    return terms.map(t => ({
      value: t.term,
      confidence: 0.1,
      reasoning: 'Batch call failed',
      cost: 0
    }));
  }
}
```

---

### 3. Database Schema

```sql
-- Table pour tracking unknowns
CREATE TABLE deadstock.unknown_terms (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  
  -- Term info
  term TEXT NOT NULL,
  category TEXT NOT NULL CHECK (category IN ('material', 'color', 'pattern')),
  source_platform TEXT, -- 'my_little_coupon', 'the_fabric_sales', etc.
  
  -- Occurrences tracking
  occurrences INT DEFAULT 1,
  first_seen_at TIMESTAMP DEFAULT NOW(),
  last_seen_at TIMESTAMP DEFAULT NOW(),
  contexts JSONB DEFAULT '[]'::jsonb, -- Array of full text contexts
  
  -- LLM fallback tracking
  llm_suggestion TEXT,
  llm_confidence FLOAT,
  llm_reasoning TEXT,
  llm_cost_total FLOAT DEFAULT 0, -- Cumulative cost in $
  llm_calls_count INT DEFAULT 0,
  
  -- Human review
  status TEXT DEFAULT 'pending' CHECK (
    status IN ('pending', 'reviewing', 'approved', 'rejected', 'skipped')
  ),
  human_mapping TEXT,
  is_regex BOOLEAN DEFAULT false,
  regex_pattern TEXT,
  reviewed_by UUID REFERENCES auth.users(id),
  reviewed_at TIMESTAMP,
  review_notes TEXT,
  
  -- Dictionary integration
  added_to_dict BOOLEAN DEFAULT false,
  added_to_dict_at TIMESTAMP,
  dict_type TEXT CHECK (dict_type IN ('exact', 'regex', NULL)),
  
  -- Metadata
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  
  UNIQUE(term, category)
);

-- Indexes
CREATE INDEX idx_unknown_status ON deadstock.unknown_terms(status);
CREATE INDEX idx_unknown_occurrences ON deadstock.unknown_terms(occurrences DESC);
CREATE INDEX idx_unknown_confidence ON deadstock.unknown_terms(llm_confidence DESC);
CREATE INDEX idx_unknown_category ON deadstock.unknown_terms(category);
CREATE INDEX idx_unknown_platform ON deadstock.unknown_terms(source_platform);

-- Function pour update last_seen_at
CREATE OR REPLACE FUNCTION update_unknown_term_timestamp()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER unknown_terms_updated_at
  BEFORE UPDATE ON deadstock.unknown_terms
  FOR EACH ROW
  EXECUTE FUNCTION update_unknown_term_timestamp();

-- Table pour regression test snapshots
CREATE TABLE deadstock.normalization_snapshots (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  created_at TIMESTAMP DEFAULT NOW(),
  dictionary_version TEXT,
  total_textiles INT,
  changes_detected INT,
  changes_detail JSONB,
  applied BOOLEAN DEFAULT false,
  applied_at TIMESTAMP,
  notes TEXT
);

-- Table pour tracking co√ªts LLM
CREATE TABLE deadstock.llm_cost_tracking (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  date DATE NOT NULL,
  category TEXT,
  calls_count INT DEFAULT 0,
  total_cost FLOAT DEFAULT 0,
  avg_confidence FLOAT,
  created_at TIMESTAMP DEFAULT NOW(),
  
  UNIQUE(date, category)
);
```

---

### 4. Logging Service

```typescript
// src/lib/scraping/common/log-unknown.ts

import { createScraperClient } from '@/lib/supabase/client';

interface LogUnknownParams {
  term: string;
  category: 'material' | 'color' | 'pattern';
  source_platform?: string;
  context?: string;
  llm_suggestion?: string;
  llm_confidence?: number;
  llm_reasoning?: string;
  llm_cost?: number;
}

export async function logUnknownTerm(params: LogUnknownParams) {
  const supabase = createScraperClient();
  
  try {
    // Check if already exists
    const { data: existing } = await supabase
      .from('unknown_terms')
      .select('*')
      .eq('term', params.term)
      .eq('category', params.category)
      .single();
  
    if (existing) {
      // Update existing
      const newContexts = existing.contexts || [];
      if (params.context && !newContexts.includes(params.context)) {
        newContexts.push(params.context);
      }
    
      await supabase
        .from('unknown_terms')
        .update({
          occurrences: existing.occurrences + 1,
          last_seen_at: new Date().toISOString(),
          contexts: newContexts,
          llm_suggestion: params.llm_suggestion || existing.llm_suggestion,
          llm_confidence: params.llm_confidence || existing.llm_confidence,
          llm_reasoning: params.llm_reasoning || existing.llm_reasoning,
          llm_cost_total: existing.llm_cost_total + (params.llm_cost || 0),
          llm_calls_count: existing.llm_calls_count + (params.llm_cost ? 1 : 0)
        })
        .eq('id', existing.id);
    } else {
      // Insert new
      await supabase
        .from('unknown_terms')
        .insert({
          term: params.term,
          category: params.category,
          source_platform: params.source_platform,
          contexts: params.context ? [params.context] : [],
          llm_suggestion: params.llm_suggestion,
          llm_confidence: params.llm_confidence,
          llm_reasoning: params.llm_reasoning,
          llm_cost_total: params.llm_cost || 0,
          llm_calls_count: params.llm_cost ? 1 : 0
        });
    }
  
  } catch (error) {
    console.error('Error logging unknown term:', error);
    // Non-blocking, just log
  }
}
```

---

### 5. Interface Supervision

#### API Routes

```typescript
// app/api/admin/tuning/unknowns/route.ts

import { NextResponse } from 'next/server';
import { createScraperClient } from '@/lib/supabase/client';

export async function GET(request: Request) {
  const { searchParams } = new URL(request.url);
  const status = searchParams.get('status') || 'pending';
  const category = searchParams.get('category');
  
  const supabase = createScraperClient();
  
  let query = supabase
    .from('unknown_terms')
    .select('*')
    .eq('status', status)
    .order('occurrences', { ascending: false });
  
  if (category) {
    query = query.eq('category', category);
  }
  
  const { data, error } = await query;
  
  if (error) {
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
  
  return NextResponse.json({ unknowns: data });
}

// app/api/admin/tuning/suggest-batch/route.ts

import { NextResponse } from 'next/server';
import { normalizeBatch } from '@/lib/ai/normalize-llm';

export async function POST(request: Request) {
  const { terms } = await request.json();
  
  // Call LLM batch
  const suggestions = await normalizeBatch(terms);
  
  // Update DB avec suggestions
  const supabase = createScraperClient();
  
  for (const suggestion of suggestions) {
    await supabase
      .from('unknown_terms')
      .update({
        llm_suggestion: suggestion.value,
        llm_confidence: suggestion.confidence,
        llm_reasoning: suggestion.reasoning,
        llm_cost_total: sql`llm_cost_total + ${suggestion.cost}`,
        llm_calls_count: sql`llm_calls_count + 1`
      })
      .eq('term', suggestion.term);
  }
  
  return NextResponse.json({ suggestions });
}

// app/api/admin/tuning/approve/route.ts

import { NextResponse } from 'next/server';

export async function POST(request: Request) {
  const { id, mapping, isRegex, regexPattern } = await request.json();
  
  const supabase = createScraperClient();
  
  // Update unknown_terms
  await supabase
    .from('unknown_terms')
    .update({
      status: 'approved',
      human_mapping: mapping,
      is_regex: isRegex,
      regex_pattern: regexPattern,
      reviewed_at: new Date().toISOString(),
      added_to_dict: true,
      added_to_dict_at: new Date().toISOString(),
      dict_type: isRegex ? 'regex' : 'exact'
    })
    .eq('id', id);
  
  // TODO: Update dictionary file
  // (voir section suivante)
  
  return NextResponse.json({ success: true });
}
```

#### React Component

```tsx
// app/admin/tuning/page.tsx

'use client';

import { useState, useEffect } from 'react';

interface UnknownTerm {
  id: string;
  term: string;
  category: string;
  occurrences: number;
  contexts: string[];
  llm_suggestion: string | null;
  llm_confidence: number | null;
  status: string;
}

export default function TuningPage() {
  const [unknowns, setUnknowns] = useState<UnknownTerm[]>([]);
  const [loading, setLoading] = useState(false);
  
  useEffect(() => {
    loadUnknowns();
  }, []);
  
  async function loadUnknowns() {
    const res = await fetch('/api/admin/tuning/unknowns?status=pending');
    const data = await res.json();
    setUnknowns(data.unknowns);
  }
  
  async function getSuggestions() {
    setLoading(true);
  
    const terms = unknowns.map(u => ({
      term: u.term,
      category: u.category,
      context: u.contexts[0]
    }));
  
    await fetch('/api/admin/tuning/suggest-batch', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ terms })
    });
  
    await loadUnknowns(); // Reload avec suggestions
    setLoading(false);
  }
  
  async function approve(id: string, mapping: string, isRegex: boolean = false) {
    await fetch('/api/admin/tuning/approve', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ id, mapping, isRegex })
    });
  
    await loadUnknowns();
  }
  
  return (
    <div className="p-8 max-w-6xl mx-auto">
      <h1 className="text-3xl font-bold mb-4">Tuning Dashboard</h1>
    
      <div className="mb-6">
        <button
          onClick={getSuggestions}
          disabled={loading}
          className="bg-blue-600 text-white px-4 py-2 rounded"
        >
          {loading ? 'Getting Suggestions...' : 'ü§ñ Get LLM Suggestions for All'}
        </button>
      </div>
    
      <div className="space-y-4">
        {unknowns.map(unknown => (
          <div key={unknown.id} className="border rounded p-4">
            <div className="flex justify-between items-start mb-2">
              <div>
                <h3 className="font-semibold text-lg">
                  "{unknown.term}" 
                  <span className="text-sm text-gray-500 ml-2">
                    ({unknown.category}, {unknown.occurrences}√ó occurrences)
                  </span>
                </h3>
              </div>
            </div>
          
            {unknown.contexts.length > 0 && (
              <div className="mb-3">
                <p className="text-sm text-gray-600">Contexts:</p>
                <ul className="text-sm list-disc list-inside">
                  {unknown.contexts.slice(0, 2).map((ctx, i) => (
                    <li key={i} className="text-gray-700">{ctx}</li>
                  ))}
                </ul>
              </div>
            )}
          
            {unknown.llm_suggestion && (
              <div className="mb-3 p-2 bg-blue-50 rounded">
                <p className="text-sm font-medium">
                  LLM Suggestion: "{unknown.llm_suggestion}"
                  {unknown.llm_confidence && (
                    <span className="text-gray-600 ml-2">
                      ({(unknown.llm_confidence * 100).toFixed(0)}% confident)
                    </span>
                  )}
                </p>
              </div>
            )}
          
            <div className="flex gap-2">
              <button
                onClick={() => approve(unknown.id, unknown.llm_suggestion!)}
                className="bg-green-600 text-white px-3 py-1 rounded text-sm"
              >
                ‚úÖ Approve
              </button>
              <button
                className="bg-gray-300 text-gray-700 px-3 py-1 rounded text-sm"
              >
                ‚úèÔ∏è Edit
              </button>
              <button
                className="bg-red-600 text-white px-3 py-1 rounded text-sm"
              >
                ‚ùå Reject
              </button>
            </div>
          </div>
        ))}
      </div>
    </div>
  );
}
```

---

### 6. Tests Non-R√©gression

```typescript
// scripts/test-regression.ts

import './load-env';
import { createScraperClient } from '../src/lib/supabase/client';
import { extractMaterialType, extractColor } from '../src/lib/scraping/common/normalize';

interface Change {
  textile_id: string;
  name: string;
  field: 'material' | 'color';
  old_value: string | null;
  new_value: string | null;
  impact: 'improvement' | 'regression' | 'lateral';
}

async function runRegressionTest() {
  console.log('üß™ Running Non-Regression Test...\n');
  
  const supabase = createScraperClient();
  
  // 1. Create snapshot
  const snapshotId = await createSnapshot();
  
  // 2. Fetch all textiles
  const { data: textiles, error } = await supabase
    .from('textiles')
    .select('id, name, description, material_type, color');
  
  if (error) {
    console.error('Error fetching textiles:', error);
    return;
  }
  
  console.log(`üìä Testing ${textiles.length} textiles...\n`);
  
  // 3. Re-normalize with current dictionaries
  const changes: Change[] = [];
  
  for (const textile of textiles) {
    const fullText = `${textile.name} ${textile.description || ''}`;
  
    // Re-normalize (without LLM fallback for test)
    const newMaterial = await extractMaterialType(fullText, { 
      enableLLMFallback: false 
    });
    const newColor = await extractColor(fullText, { 
      enableLLMFallback: false 
    });
  
    // Detect changes
    if (textile.material_type !== newMaterial) {
      changes.push({
        textile_id: textile.id,
        name: textile.name,
        field: 'material',
        old_value: textile.material_type,
        new_value: newMaterial,
        impact: classifyChange(textile.material_type, newMaterial)
      });
    }
  
    if (textile.color !== newColor) {
      changes.push({
        textile_id: textile.id,
        name: textile.name,
        field: 'color',
        old_value: textile.color,
        new_value: newColor,
        impact: classifyChange(textile.color, newColor)
      });
    }
  }
  
  // 4. Classify changes
  const improvements = changes.filter(c => c.impact === 'improvement');
  const regressions = changes.filter(c => c.impact === 'regression');
  const laterals = changes.filter(c => c.impact === 'lateral');
  
  // 5. Generate report
  console.log('‚îÄ'.repeat(60));
  console.log(`\nüìã Regression Test Results:`);
  console.log(`   Total textiles: ${textiles.length}`);
  console.log(`   Unchanged: ${textiles.length - changes.length}`);
  console.log(`   Changed: ${changes.length} (${(changes.length/textiles.length*100).toFixed(1)}%)\n`);
  
  console.log(`   ‚úÖ Improvements: ${improvements.length} (unknown ‚Üí known)`);
  console.log(`   ‚ùå Regressions: ${regressions.length} (known ‚Üí unknown)`);
  console.log(`   üîÑ Lateral: ${laterals.length} (value changed)\n`);
  
  // 6. Show regressions details
  if (regressions.length > 0) {
    console.log(`‚ö†Ô∏è  REGRESSIONS (review required):\n`);
    regressions.forEach((c, i) => {
      console.log(`${i+1}. "${c.name}"`);
      console.log(`   ${c.field}: "${c.old_value}" ‚Üí "${c.new_value}"`);
      console.log();
    });
  }
  
  // 7. Save snapshot
  await saveSnapshot(snapshotId, {
    total: textiles.length,
    changes: changes.length,
    improvements: improvements.length,
    regressions: regressions.length,
    changes_detail: changes
  });
  
  // 8. Return result
  return {
    total: textiles.length,
    changes,
    improvements,
    regressions,
    laterals,
    snapshot_id: snapshotId
  };
}

function classifyChange(
  oldValue: string | null, 
  newValue: string | null
): 'improvement' | 'regression' | 'lateral' {
  
  if (oldValue === null && newValue !== null) return 'improvement';
  if (oldValue !== null && newValue === null) return 'regression';
  return 'lateral';
}

async function createSnapshot(): Promise<string> {
  const supabase = createScraperClient();
  
  const { data, error } = await supabase
    .from('normalization_snapshots')
    .insert({
      dictionary_version: new Date().toISOString()
    })
    .select()
    .single();
  
  if (error) throw error;
  
  return data.id;
}

async function saveSnapshot(id: string, results: any) {
  const supabase = createScraperClient();
  
  await supabase
    .from('normalization_snapshots')
    .update({
      total_textiles: results.total,
      changes_detected: results.changes,
      changes_detail: results.changes_detail
    })
    .eq('id', id);
}

// Run
runRegressionTest()
  .then(() => console.log('\n‚úÖ Test complete'))
  .catch(err => console.error('\n‚ùå Test failed:', err));
```

---

## Flow de Donn√©es

### Scraping Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Scraper starts (daily cron)                ‚îÇ
‚îÇ                                                ‚îÇ
‚îÇ    scrape-mlc-to-db.ts                        ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ    Fetch 500 products from MLC API            ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ    For each product:                          ‚îÇ
‚îÇ      - Extract title, description             ‚îÇ
‚îÇ      - Call normalize(text, 'material')       ‚îÇ
‚îÇ      - Call normalize(text, 'color')          ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ    normalize() checks dictionary              ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄFound?‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ
‚îÇ    ‚ñº              ‚ñº                            ‚îÇ
‚îÇ   YES            NO                            ‚îÇ
‚îÇ    ‚îÇ              ‚îÇ                            ‚îÇ
‚îÇ    ‚îÇ              ‚îú‚îÄ Call LLM (2s, $0.003)   ‚îÇ
‚îÇ    ‚îÇ              ‚îú‚îÄ Log to unknown_terms     ‚îÇ
‚îÇ    ‚îÇ              ‚îî‚îÄ Return LLM result        ‚îÇ
‚îÇ    ‚îÇ                                           ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                   ‚ñº                            ‚îÇ
‚îÇ    Insert textile with normalized data        ‚îÇ
‚îÇ                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Daily stats:
- Dictionary hits: 425/500 (85%)
- LLM fallback: 75/500 (15%)
- Cost: $0.225
- Duration: ~5 minutes
```

### Supervision Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Weekly Review (Thomas, 30 minutes)            ‚îÇ
‚îÇ                                                ‚îÇ
‚îÇ 1. Email notification: "20 unknowns pending"  ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ 2. Open /admin/tuning                         ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ 3. Click "Get LLM Suggestions"                ‚îÇ
‚îÇ    - Batch call Claude (1 API call)          ‚îÇ
‚îÇ    - Get 20 suggestions in 3 seconds         ‚îÇ
‚îÇ    - Cost: $0.05                              ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ 4. Review each suggestion:                    ‚îÇ
‚îÇ    - "lilas" ‚Üí "lilac" ‚úì Approve             ‚îÇ
‚îÇ    - "√©cru" ‚Üí "ecru" ‚úì Approve               ‚îÇ
‚îÇ    - "bouclette" ‚Üí "boucle" ‚úèÔ∏è Edit to "knit" ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ 5. Click "Run Non-Regression Test"            ‚îÇ
‚îÇ    - Script analyzes 150 textiles            ‚îÇ
‚îÇ    - Reports: 12 improvements, 0 regressions ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ 6. Click "Apply Changes"                      ‚îÇ
‚îÇ    - Dictionary updated                       ‚îÇ
‚îÇ    - Database updated                         ‚îÇ
‚îÇ         ‚Üì                                      ‚îÇ
‚îÇ 7. Next scraping uses new dictionary         ‚îÇ
‚îÇ    - Coverage 85% ‚Üí 92%                       ‚îÇ
‚îÇ    - LLM calls reduce 15% ‚Üí 8%                ‚îÇ
‚îÇ    - Cost drops $7/month ‚Üí $3.60/month        ‚îÇ
‚îÇ                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Roadmap

### Phase 1: MVP Dictionnaire (Cette semaine - 4h) ‚úÖ

**Objectif** : Quality 70% ‚Üí 80%

**Tasks** :

* [X] Table `unknown_terms` SQL
* [X] Dictionnaire JSON (materials, colors)
* [X] Fonction `extractMaterialType()` avec logging
* [X] Script CLI `scripts/analyze-unknowns.ts`
* [X] Enrichir dictionnaire manuellement (10-15 termes)
* [X] Re-scraper MLC

**R√©sultat** : Fondations syst√®me, quality +10%

---

### Phase 2: LLM Fallback Temps R√©el (Semaine 2 - 3h)

**Objectif** : Quality 80% ‚Üí 95%

**Tasks** :

* [ ] Service `normalize-llm.ts`
* [ ] Claude API integration
* [ ] Config prompts templates
* [ ] Update `extractMaterialType()` avec LLM fallback
* [ ] Enhanced logging (llm_suggestion, cost)
* [ ] Monitoring dashboard co√ªts

**R√©sultat** : 100% coverage imm√©diat

---

### Phase 3: Interface Supervision (Semaine 2-3 - 1 jour)

**Objectif** : Workflow humain efficace

**Tasks** :

* [ ] Page `/admin/tuning`
* [ ] API route `/api/admin/tuning/unknowns`
* [ ] API route `/api/admin/tuning/suggest-batch`
* [ ] API route `/api/admin/tuning/approve`
* [ ] React component liste unknowns
* [ ] Batch LLM suggestions button
* [ ] Approve/reject/edit flows

**R√©sultat** : Review 50 termes en 20 min

---

### Phase 4: Tests Non-R√©gression (Semaine 3 - 3h)

**Objectif** : Confiance updates

**Tasks** :

* [ ] Script `scripts/test-regression.ts`
* [ ] Snapshot system (DB)
* [ ] Change detection logic
* [ ] Classification (improvement/regression/lateral)
* [ ] Report g√©n√©ration
* [ ] UI confirmation avant apply

**R√©sultat** : Zero surprises

---

### Phase 5: Regex Patterns (Phase 3 projet - 2 jours)

**Objectif** : Coverage 95% ‚Üí 98%

**Tasks** :

* [ ] Support regex dans dictionnaires
* [ ] Priority matching system
* [ ] UI regex builder
* [ ] Test regex en temps r√©el
* [ ] Migration exact ‚Üí regex patterns

**R√©sultat** : Gestion patterns complexes

---

### Phase 6: Prompt Tuning (Phase 4+ - Continu)

**Objectif** : Am√©lioration continue LLM

**Tasks** :

* [ ] Interface √©dition prompts
* [ ] Template variables
* [ ] A/B testing prompts
* [ ] Analytics accuracy par prompt
* [ ] Version control prompts

**R√©sultat** : Fine-tuning continu

---

## Monitoring & M√©triques

### Dashboard Metrics

```typescript
// Metrics √† tracker

interface DailyMetrics {
  date: Date;
  
  // Quality
  quality_score: number;
  materials_detected_pct: number;
  colors_detected_pct: number;
  
  // Coverage
  dictionary_coverage_pct: number; // % hits sans LLM
  llm_fallback_pct: number;
  
  // Costs
  llm_calls_count: number;
  llm_cost_total: number;
  
  // Unknowns
  unknowns_pending: number;
  unknowns_reviewed: number;
  
  // Textiles
  total_textiles: number;
}
```

### Alerts

```typescript
// Alert triggers

const ALERTS = {
  high_cost: {
    condition: (metrics) => metrics.llm_cost_total > 15, // $15/mois
    action: 'Email Thomas: LLM costs high, review unknowns'
  },
  
  low_coverage: {
    condition: (metrics) => metrics.dictionary_coverage_pct < 80,
    action: 'Email Thomas: Dictionary coverage dropping'
  },
  
  pending_review: {
    condition: (metrics) => metrics.unknowns_pending > 50,
    action: 'Email Thomas: 50+ unknowns need review'
  },
  
  quality_drop: {
    condition: (metrics) => metrics.quality_score < 90,
    action: 'Email Thomas: Quality score below 90%'
  }
};
```

---

## Troubleshooting

### Probl√®me 1 : Co√ªts LLM Trop √âlev√©s

**Sympt√¥me** : >$20/mois apr√®s 1 mois

**Causes possibles** :

1. Coverage dictionnaire pas assez augment√©
2. Nouvelle source avec beaucoup unknowns
3. LLM appel√© m√™me pour termes connus (bug)

**Debug** :

```sql
-- Check coverage
SELECT 
  COUNT(*) FILTER (WHERE llm_calls_count > 0) as llm_calls,
  COUNT(*) as total,
  (COUNT(*) FILTER (WHERE llm_calls_count > 0)::float / COUNT(*)) * 100 as pct
FROM deadstock.unknown_terms;

-- Check co√ªts par cat√©gorie
SELECT 
  category,
  SUM(llm_cost_total) as total_cost,
  AVG(llm_confidence) as avg_confidence
FROM deadstock.unknown_terms
GROUP BY category;
```

**Solutions** :

* Review unknowns plus fr√©quemment
* Enrichir dictionnaire prioritairement termes haute fr√©quence
* V√©rifier pas de bug (LLM appel√© inutilement)

---

### Probl√®me 2 : Quality Score Ne Monte Pas

**Sympt√¥me** : Quality reste 85% apr√®s enrichissement

**Causes possibles** :

1. Dictionnaire enrichi mais pas d√©ploy√©
2. Tests non-r√©gression pas appliqu√©s
3. Nouveaux textiles avec nouveaux termes

**Debug** :

```sql
-- Check textiles avec unknowns
SELECT 
  material_type,
  COUNT(*) 
FROM deadstock.textiles 
WHERE material_type IS NULL OR material_type = 'unknown'
GROUP BY material_type;
```

**Solutions** :

* V√©rifier dictionnaire d√©ploy√©
* Re-scraper textiles existants
* Analyser nouveaux unknowns

---

### Probl√®me 3 : LLM Suggestions Mauvaises

**Sympt√¥me** : LLM sugg√®re "purple" au lieu de "lilac"

**Cause** : Prompt pas assez sp√©cifique

**Solution** :

* Am√©liorer prompt template
* Ajouter examples dans prompt
* Ajuster temperature (plus bas = plus d√©terministe)

---

**Fin Documentation Technique**

**Version** : 1.0

**Prochaine R√©vision** : Apr√®s Phase 2 (LLM fallback impl√©ment√©)
