# SESSION 3 : NORMALISATION INTELLIGENTE + SUPERVISION

**DurÃ©e estimÃ©e** : 4-6 heures  
**PrÃ©requis** : Session 2 complÃ©tÃ©e (Scraping System opÃ©rationnel)  
**Objectif** : IntÃ©grer le systÃ¨me de normalisation avec dictionnaires + LLM fallback

---

## ğŸ¯ Vision StratÃ©gique

### Architecture Multi-Couches

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: RAW DATA (Shopify brut)                      â”‚
â”‚  â”œâ”€ raw_data (jsonb) - DonnÃ©es originales conservÃ©es   â”‚
â”‚  â””â”€ source_product_id, source_platform                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 2: INTELLIGENT NORMALIZATION                     â”‚
â”‚  â”œâ”€ Dictionnaires FRâ†’EN, ESâ†’EN (ADR-002)              â”‚
â”‚  â”œâ”€ LLM Fallback pour unknowns (ADR-004)              â”‚
â”‚  â”œâ”€ Confidence scoring                                  â”‚
â”‚  â””â”€ Flags pour supervision                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 3: NORMALIZED DATA (English)                     â”‚
â”‚  â”œâ”€ material_type: "cotton" âœ…                          â”‚
â”‚  â”œâ”€ color: "blue" âœ…                                    â”‚
â”‚  â”œâ”€ pattern: "striped" âœ…                               â”‚
â”‚  â””â”€ composition: {"cotton": 80, "polyester": 20}       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 4: HUMAN SUPERVISION (ADR-006)                   â”‚
â”‚  â”œâ”€ Admin reviews unknowns avec contexte enrichi       â”‚
â”‚  â”œâ”€ Approves/corrects mappings                         â”‚
â”‚  â””â”€ System apprend des corrections                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Plan Session 3

### Ã‰tape 1 : Dictionnaires de Normalisation (1h30)

#### 1.1 Structure des fichiers

```
src/lib/normalization/
â”œâ”€â”€ dictionaries/
â”‚   â”œâ”€â”€ materials.ts      # FRâ†’EN, ENâ†’EN, ESâ†’EN
â”‚   â”œâ”€â”€ colors.ts         # FRâ†’EN, ENâ†’EN, ESâ†’EN
â”‚   â”œâ”€â”€ patterns.ts       # FRâ†’EN, ENâ†’EN, ESâ†’EN
â”‚   â””â”€â”€ types.ts          # Types TypeScript
â”‚
â”œâ”€â”€ normalize.ts          # Fonctions de normalisation
â””â”€â”€ types.ts              # Interfaces communes
```

#### 1.2 Contenu des dictionnaires

**materials.ts** :
```typescript
export const materialDictionary = {
  fr: {
    // Fibres naturelles
    'coton': 'cotton',
    'soie': 'silk',
    'laine': 'wool',
    'lin': 'linen',
    'cachemire': 'cashmere',
    
    // Fibres synthÃ©tiques
    'polyester': 'polyester',
    'viscose': 'viscose',
    'Ã©lasthanne': 'elastane',
    'nylon': 'nylon',
    
    // Blends
    'coton-polyester': 'cotton blend',
    'laine-cachemire': 'wool blend',
    // ... ~30-50 termes
  },
  en: {
    'cotton': 'cotton', // passthrough
    'silk': 'silk',
    // ...
  },
  es: {
    'algodÃ³n': 'cotton',
    'seda': 'silk',
    // ...
  }
};
```

**colors.ts** :
```typescript
export const colorDictionary = {
  fr: {
    // Couleurs de base
    'blanc': 'white',
    'noir': 'black',
    'rouge': 'red',
    'bleu': 'blue',
    'vert': 'green',
    'jaune': 'yellow',
    
    // Nuances
    'bleu marine': 'navy blue',
    'bleu ciel': 'sky blue',
    'rouge bordeaux': 'burgundy',
    'rose poudrÃ©': 'powder pink',
    'gris anthracite': 'charcoal gray',
    
    // Textile-specific
    'Ã©cru': 'ecru',
    'lilas': 'lilac',
    'turquoise': 'turquoise',
    // ... ~50-100 termes
  },
  // ... en, es
};
```

**patterns.ts** :
```typescript
export const patternDictionary = {
  fr: {
    'uni': 'solid',
    'rayÃ©': 'striped',
    'Ã  carreaux': 'checkered',
    'fleuri': 'floral',
    'pois': 'polka dot',
    'imprimÃ©': 'printed',
    'jacquard': 'jacquard',
    // ... ~30 termes
  },
  // ... en, es
};
```

---

### Ã‰tape 2 : Fonctions de Normalisation (1h)

#### 2.1 normalize.ts

```typescript
export interface NormalizationResult {
  normalized: string | null;
  original: string;
  confidence: number; // 0-1
  method: 'dictionary_exact' | 'dictionary_synonym' | 'llm_fallback' | 'failed';
  alternatives?: string[];
}

export interface TextileNormalization {
  material: NormalizationResult | null;
  color: NormalizationResult | null;
  pattern: NormalizationResult | null;
  needsReview: boolean;
  reviewReasons: Array<{
    field: string;
    reason: string;
    details?: any;
  }>;
  qualityScore: number;
}

/**
 * Normalize Shopify product tags/title to structured data
 */
export async function normalizeShopifyProduct(
  product: ShopifyProduct,
  sourceLang: 'fr' | 'en' | 'es' = 'en'
): Promise<TextileNormalization> {
  // Extract material from tags/title
  const material = await normalizeMaterial(
    extractMaterialHints(product),
    sourceLang
  );
  
  // Extract color from tags/title
  const color = await normalizeColor(
    extractColorHints(product),
    sourceLang
  );
  
  // Extract pattern from tags/title
  const pattern = await normalizePattern(
    extractPatternHints(product),
    sourceLang
  );
  
  // Determine if needs review
  const needsReview = (
    material?.confidence < 0.7 ||
    color?.confidence < 0.7 ||
    pattern?.confidence < 0.7
  );
  
  // Calculate quality score
  const qualityScore = calculateQualityScore({
    material,
    color,
    pattern
  });
  
  return {
    material,
    color,
    pattern,
    needsReview,
    reviewReasons: buildReviewReasons({ material, color, pattern }),
    qualityScore
  };
}

/**
 * Normalize material with dictionary + LLM fallback
 */
async function normalizeMaterial(
  hints: string[],
  sourceLang: string
): Promise<NormalizationResult | null> {
  // Try dictionary first (fast path)
  for (const hint of hints) {
    const dictResult = tryDictionary(hint, sourceLang, materialDictionary);
    if (dictResult) {
      return {
        normalized: dictResult,
        original: hint,
        confidence: 0.95,
        method: 'dictionary_exact'
      };
    }
  }
  
  // LLM fallback (slow path) - TODO: implement in Phase 2
  // For now, return null and log for supervision
  return null;
}
```

---

### Ã‰tape 3 : Migration 009 - Colonnes de Normalisation (30min)

```sql
-- Migration 009: Add normalization metadata to textiles

-- Original values (pour rÃ©fÃ©rence)
ALTER TABLE deadstock.textiles
ADD COLUMN material_original TEXT,
ADD COLUMN color_original TEXT,
ADD COLUMN pattern_original TEXT,
ADD COLUMN tags_original TEXT[];

-- Confidence scores
ADD COLUMN material_confidence DECIMAL(3,2),
ADD COLUMN color_confidence DECIMAL(3,2),
ADD COLUMN pattern_confidence DECIMAL(3,2);

-- Supervision flags
ADD COLUMN needs_review BOOLEAN DEFAULT FALSE,
ADD COLUMN review_reasons JSONB,
ADD COLUMN reviewed_at TIMESTAMPTZ,
ADD COLUMN reviewed_by UUID;

-- Indexes
CREATE INDEX idx_textiles_needs_review 
ON deadstock.textiles(needs_review) 
WHERE needs_review = TRUE;

CREATE INDEX idx_textiles_material_type 
ON deadstock.textiles(material_type) 
WHERE material_type IS NOT NULL;

CREATE INDEX idx_textiles_color 
ON deadstock.textiles(color) 
WHERE color IS NOT NULL;
```

---

### Ã‰tape 4 : IntÃ©gration dans scrapingRepo (45min)

#### 4.1 Modifier saveProducts()

```typescript
async saveProducts(
  products: ShopifyProduct[],
  siteUrl: string,
  jobId: string,
  sourceLang: 'fr' | 'en' | 'es' = 'en'
): Promise<{ saved: number; updated: number; skipped: number }> {
  // ...
  
  for (const product of products) {
    // NOUVEAU : Normalisation avant sauvegarde
    const normalization = await normalizeShopifyProduct(product, sourceLang);
    
    const textileData = {
      // Raw
      raw_data: product,
      source_product_id: product.id.toString(),
      
      // Normalized (Layer 2)
      material_type: normalization.material?.normalized,
      material_original: normalization.material?.original,
      material_confidence: normalization.material?.confidence,
      
      color: normalization.color?.normalized,
      color_original: normalization.color?.original,
      color_confidence: normalization.color?.confidence,
      
      pattern: normalization.pattern?.normalized,
      pattern_original: normalization.pattern?.original,
      pattern_confidence: normalization.pattern?.confidence,
      
      tags_original: Array.isArray(product.tags) 
        ? product.tags 
        : product.tags.split(',').map(t => t.trim()),
      
      // Supervision
      needs_review: normalization.needsReview,
      review_reasons: normalization.reviewReasons,
      
      // Quality
      data_quality_score: Math.round(normalization.qualityScore),
      
      // ... autres champs
    };
    
    // Insert/Update...
  }
}
```

---

### Ã‰tape 5 : Tests & Validation (1h)

#### 5.1 Test avec The Fabric Sales

```powershell
# Test normalization sur 20 produits
npm run scrape thefabricsales.com --collection abstract --limit 20

# VÃ©rifier en DB
SELECT 
  name,
  material_type, material_original, material_confidence,
  color, color_original, color_confidence,
  needs_review,
  data_quality_score
FROM deadstock.textiles
WHERE source_platform = 'thefabricsales.com'
ORDER BY scraped_at DESC
LIMIT 20;
```

#### 5.2 MÃ©triques de succÃ¨s

- âœ… 80%+ des produits ont `material_type` normalisÃ©
- âœ… 70%+ des produits ont `color` normalisÃ©
- âœ… Confidence moyenne > 0.85
- âœ… `needs_review` < 30% des produits

---

## ğŸ“Š Structure finale de la donnÃ©e

### Exemple : Product bien normalisÃ©

```json
{
  "name": "Manon Burgundy Red Check Wool Blend Fabric",
  
  // Normalized (searchable)
  "material_type": "wool",
  "color": "red",
  "pattern": "check",
  
  // Original (for reference)
  "material_original": "wool-blend",
  "color_original": "burgundy",
  "pattern_original": "checked",
  "tags_original": ["wool-blend", "burgundy", "checked", "designer"],
  
  // Confidence
  "material_confidence": 0.95,
  "color_confidence": 0.80,
  "pattern_confidence": 0.90,
  
  // Supervision
  "needs_review": false,
  "review_reasons": [],
  "data_quality_score": 88,
  
  // Raw (complete data)
  "raw_data": { /* Full Shopify object */ }
}
```

### Exemple : Product Ã  reviewer

```json
{
  "name": "Viscose-Like Mystery Fabric",
  
  // Normalized
  "material_type": null,
  "color": "blue",
  "pattern": null,
  
  // Original
  "material_original": "viscose-like-fabric",
  "color_original": "azure",
  "pattern_original": "floral-striped",
  "tags_original": ["viscose-like-fabric", "azure", "floral-striped"],
  
  // Confidence
  "material_confidence": 0.0,
  "color_confidence": 0.85,
  "pattern_confidence": 0.50,
  
  // Supervision
  "needs_review": true,
  "review_reasons": [
    {
      "field": "material_type",
      "reason": "unknown_term",
      "original_value": "viscose-like-fabric",
      "suggestions": ["viscose", "polyester", "synthetic"]
    },
    {
      "field": "pattern",
      "reason": "multiple_matches",
      "detected": ["floral", "striped"]
    }
  ],
  "data_quality_score": 55
}
```

---

## ğŸš€ Livrables Session 3

### Fichiers Ã  crÃ©er

- [ ] `src/lib/normalization/dictionaries/materials.ts`
- [ ] `src/lib/normalization/dictionaries/colors.ts`
- [ ] `src/lib/normalization/dictionaries/patterns.ts`
- [ ] `src/lib/normalization/normalize.ts`
- [ ] `src/lib/normalization/types.ts`
- [ ] `database/migrations/009_normalization_metadata.sql`

### Fichiers Ã  modifier

- [ ] `src/features/admin/infrastructure/scrapingRepo.ts` (intÃ©grer normalisation)
- [ ] `src/features/admin/services/scrapingService.ts` (passer sourceLang)

### Tests Ã  effectuer

- [ ] Test normalisation TFS (EN) - 20 produits
- [ ] Test normalisation MLC (FR) - 20 produits (si connexion stable)
- [ ] VÃ©rifier donnÃ©es en DB
- [ ] Valider mÃ©triques de qualitÃ©

---

## ğŸ“ Notes importantes

### DiffÃ©rence avec ancien systÃ¨me

**Ancien** (scripts Phase 0) :
- Normalisation ad-hoc dans chaque scraper
- Dictionnaires inline
- Pas de confidence scoring
- Pas de supervision

**Nouveau** (Session 3) :
- Normalisation centralisÃ©e rÃ©utilisable
- Dictionnaires structurÃ©s par langue
- Confidence scoring systÃ©matique
- Flags pour supervision admin
- Raw data toujours prÃ©servÃ©

### Phase 2 (Future) : LLM Fallback

Non implÃ©mentÃ© en Session 3, sera ajoutÃ© plus tard :
- Claude API pour unknowns
- Logging pour review
- Interface admin de supervision

---

## âœ… CritÃ¨res de validation Session 3

Session 3 est complÃ¨te si :
- âœ… Dictionnaires FR/EN/ES crÃ©Ã©s (30+ termes chacun)
- âœ… Fonctions de normalisation opÃ©rationnelles
- âœ… Migration 009 exÃ©cutÃ©e
- âœ… ScrapingRepo intÃ©grÃ© avec normalisation
- âœ… Test TFS : 80%+ material_type dÃ©tectÃ©
- âœ… Test TFS : 70%+ color dÃ©tectÃ©
- âœ… DonnÃ©es originales prÃ©servÃ©es (tags_original, *_original)
- âœ… Confidence scores calculÃ©s
- âœ… Flags needs_review fonctionnels

---

## ğŸ”— RÃ©fÃ©rences

- **ADR-002** : Normalisation English + i18n
- **ADR-004** : Tuning System (Dictionnaire + LLM)
- **ADR-006** : Product Context Enrichment
- **TUNING_SYSTEM.md** : Documentation systÃ¨me tuning
